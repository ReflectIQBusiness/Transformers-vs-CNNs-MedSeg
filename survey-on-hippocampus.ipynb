{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11600309,"sourceType":"datasetVersion","datasetId":7275187}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":18881.850188,"end_time":"2025-02-07T08:00:37.121973","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-02-07T02:45:55.271785","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"959e2fc1","cell_type":"code","source":"!pip install scikit-learn","metadata":{"papermill":{"duration":6.307442,"end_time":"2025-02-07T02:47:40.137763","exception":false,"start_time":"2025-02-07T02:47:33.830321","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T10:15:28.251511Z","iopub.execute_input":"2025-04-30T10:15:28.252172Z","iopub.status.idle":"2025-04-30T10:15:33.384447Z","shell.execute_reply.started":"2025-04-30T10:15:28.252146Z","shell.execute_reply":"2025-04-30T10:15:33.383537Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"id":"20fe5664","cell_type":"code","source":"!pip install --force-reinstall --user einops==0.3.2","metadata":{"papermill":{"duration":4.916061,"end_time":"2025-02-07T02:47:45.057329","exception":false,"start_time":"2025-02-07T02:47:40.141268","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T10:15:33.385827Z","iopub.execute_input":"2025-04-30T10:15:33.386049Z","iopub.status.idle":"2025-04-30T10:15:36.465271Z","shell.execute_reply.started":"2025-04-30T10:15:33.386030Z","shell.execute_reply":"2025-04-30T10:15:36.464571Z"}},"outputs":[{"name":"stdout","text":"Collecting einops==0.3.2\n  Downloading einops-0.3.2-py3-none-any.whl.metadata (10 kB)\nDownloading einops-0.3.2-py3-none-any.whl (25 kB)\nInstalling collected packages: einops\nSuccessfully installed einops-0.3.2\n","output_type":"stream"}],"execution_count":2},{"id":"128f4ecd","cell_type":"code","source":"!pip install torch torchvision nibabel","metadata":{"papermill":{"duration":3.684733,"end_time":"2025-02-07T02:47:48.746313","exception":false,"start_time":"2025-02-07T02:47:45.061580","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T10:15:36.466220Z","iopub.execute_input":"2025-04-30T10:15:36.466424Z","iopub.status.idle":"2025-04-30T10:16:49.165381Z","shell.execute_reply.started":"2025-04-30T10:15:36.466405Z","shell.execute_reply":"2025-04-30T10:16:49.164476Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\nRequirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (5.3.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\nRequirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel) (6.5.2)\nRequirement already satisfied: packaging>=20 in /usr/local/lib/python3.11/dist-packages (from nibabel) (24.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":3},{"id":"914bf542","cell_type":"code","source":"!pip install monai","metadata":{"papermill":{"duration":5.15861,"end_time":"2025-02-07T02:47:53.908680","exception":false,"start_time":"2025-02-07T02:47:48.750070","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T10:16:49.167388Z","iopub.execute_input":"2025-04-30T10:16:49.167611Z","iopub.status.idle":"2025-04-30T10:16:53.338511Z","shell.execute_reply.started":"2025-04-30T10:16:49.167592Z","shell.execute_reply":"2025-04-30T10:16:53.337814Z"}},"outputs":[{"name":"stdout","text":"Collecting monai\n  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: numpy<2.0,>=1.24 in /usr/local/lib/python3.11/dist-packages (from monai) (1.26.4)\nRequirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from monai) (2.5.1+cu124)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->monai) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->monai) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.24->monai) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0,>=1.24->monai) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0,>=1.24->monai) (2024.2.0)\nDownloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: monai\nSuccessfully installed monai-1.4.0\n","output_type":"stream"}],"execution_count":4},{"id":"4eccc6d9","cell_type":"code","source":"!pip install thop","metadata":{"papermill":{"duration":4.081817,"end_time":"2025-02-07T02:47:57.995375","exception":false,"start_time":"2025-02-07T02:47:53.913558","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T10:16:53.339384Z","iopub.execute_input":"2025-04-30T10:16:53.339583Z","iopub.status.idle":"2025-04-30T10:16:56.542856Z","shell.execute_reply.started":"2025-04-30T10:16:53.339564Z","shell.execute_reply":"2025-04-30T10:16:56.541979Z"}},"outputs":[{"name":"stdout","text":"Collecting thop\n  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from thop) (2.5.1+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->thop) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->thop) (3.0.2)\nDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\nInstalling collected packages: thop\nSuccessfully installed thop-0.1.1.post2209072238\n","output_type":"stream"}],"execution_count":5},{"id":"1e3b69b7","cell_type":"markdown","source":"# **Another try of survey**","metadata":{"papermill":{"duration":0.004061,"end_time":"2025-02-07T03:15:43.809973","exception":false,"start_time":"2025-02-07T03:15:43.805912","status":"completed"},"tags":[]}},{"id":"01643429-f102-4961-a9bf-9ced6ae0839d","cell_type":"code","source":"#!/usr/bin/env python3\n# train_hippocampus.py\n\nimport os\nimport glob\nimport time\nimport copy\nimport random\n\nimport numpy as np\nimport pandas as pd\nimport nibabel as nib\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\n# use threads instead of processes so we don't hit pickling issues\nfrom multiprocessing.dummy import Pool\n\nfrom monai.networks.nets import (\n    UNet, UNETR, SwinUNETR, AttentionUnet,\n    HighResNet, VNet, DynUNet, RegUNet, SegResNet\n)\nfrom monai.losses import DiceCELoss\nfrom monai.inferers import sliding_window_inference\n\nfrom torch.cuda.amp import autocast, GradScaler\nfrom scipy.ndimage import zoom\nfrom scipy.spatial.distance import directed_hausdorff\nfrom sklearn.metrics import confusion_matrix\nfrom thop import profile\nfrom torchmetrics import Precision, Recall, F1Score, Specificity\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.colors import ListedColormap\nfrom tensorflow.keras import callbacks\n\n# —————————————————————————————————————————————\n# 1) Config & constants\n\nDATA_ROOT   = \"/kaggle/input/task04-hippocampus/Task04_Hippocampus\"\nIMAGES_DIR  = os.path.join(DATA_ROOT, \"imagesTr\")\nLABELS_DIR  = os.path.join(DATA_ROOT, \"labelsTr\")\n\nIN_CHANNELS = 1           # one MRI volume per case\nNUM_CLASSES = 3           # 0=background,1=Anterior,2=Posterior\nLABEL_NAMES = {\n    0: \"background\",\n    1: \"Anterior\",\n    2: \"Posterior\",\n}\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nSEED   = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\n\n\n# —————————————————————————————————————————————\n# 2) Data loading\n\ndef collect_pairs(img_dir, lbl_dir):\n    imgs = sorted(glob.glob(os.path.join(img_dir, \"hippocampus_*.nii*\")))\n    lbls = sorted(glob.glob(os.path.join(lbl_dir, \"hippocampus_*.nii*\")))\n    img_dict = {os.path.splitext(os.path.basename(p))[0]: p for p in imgs}\n    lbl_dict = {os.path.splitext(os.path.basename(p))[0]: p for p in lbls}\n    keys = sorted(set(img_dict) & set(lbl_dict))\n    return [(img_dict[k], lbl_dict[k]) for k in keys]\n\ndef load_case(pair):\n    img_path, lbl_path = pair\n    img = nib.load(img_path).get_fdata().astype(np.float32)[..., None]\n    seg = nib.load(lbl_path).get_fdata().astype(np.float32)\n    mn, mx = img.min(), img.max()\n    img = (img - mn) / (mx - mn + 1e-8)\n    factors = (64/img.shape[0], 64/img.shape[1], 64/img.shape[2], 1)\n    img_rs = zoom(img, factors, order=1)\n    seg_rs = zoom(seg, factors[:3], order=0)\n    return img_rs, seg_rs.astype(np.float32), 1\n\ndef parallel_load(pairs, max_cases=None):\n    to_load = pairs if max_cases is None else pairs[:max_cases]\n    with Pool() as pool:\n        results = pool.map(load_case, to_load)\n    imgs, segs, flags = zip(*results)\n    imgs = [i for i,f in zip(imgs, flags) if f]\n    segs = [s for s,f in zip(segs, flags) if f]\n    return imgs, segs\n\nclass HippocampusDataset(Dataset):\n    def __init__(self, images, labels):\n        self.images = images\n        self.labels = labels\n    def __len__(self):\n        return len(self.images)\n    def __getitem__(self, idx):\n        img = torch.from_numpy(self.images[idx]).permute(3,0,1,2)\n        seg = torch.from_numpy(self.labels[idx]).long()\n        return {\"image\": img, \"label\": seg}\n\n\n# —————————————————————————————————————————————\n# 3) Visualization callback\n\nclass EnhancedVisCallback(callbacks.Callback):\n    def __init__(self, val_loader, num_samples=1):\n        super().__init__()\n        self.val_loader  = val_loader\n        self.num_samples = num_samples\n        # black=bg, red=Anterior, blue=Posterior\n        self.cmap = ListedColormap([\"black\",\"red\",\"blue\"])\n        self._model = None\n\n    def attach_model(self, model):\n        self._model = model\n\n    def on_epoch_end(self, epoch, logs=None):\n        if self._model is None: return\n        self._model.eval()\n        with torch.no_grad():\n            batch = next(iter(self.val_loader))\n            imgs = batch[\"image\"].to(DEVICE)\n            lbls = batch[\"label\"].cpu().numpy()\n            out  = sliding_window_inference(imgs, (64,64,64), 4, self._model)\n            preds= torch.argmax(out, dim=1).cpu().numpy()\n            i, mid = 0, imgs.shape[-1]//2\n            im = imgs.cpu().numpy()[i,0,:,:,mid]\n            gt = lbls[i,:,:,mid]\n            pr = preds[i,:,:,mid]\n            fig, ax = plt.subplots(1,3,figsize=(12,4))\n            ax[0].imshow(im, cmap=\"gray\");     ax[0].axis(\"off\"); ax[0].set_title(\"Input\")\n            ax[1].imshow(im, cmap=\"gray\"); ax[1].imshow(gt, cmap=self.cmap, alpha=0.5); ax[1].axis(\"off\"); ax[1].set_title(\"GT\")\n            ax[2].imshow(im, cmap=\"gray\"); ax[2].imshow(pr, cmap=self.cmap, alpha=0.5); ax[2].axis(\"off\"); ax[2].set_title(\"Pred\")\n            plt.tight_layout(); plt.show()\n\n\n# —————————————————————————————————————————————\n# 4) Metrics & visualizer\n\nclass MetricsTracker:\n    def __init__(self):\n        self.history = {\n            \"train_loss\":    [],\n            \"val_dice\":      [],\n            \"val_hausdorff\": [],\n            \"per_class_dice\": {f\"class_{i}\": [] for i in range(1,NUM_CLASSES)},\n            \"precision\":     [],\n            \"recall\":        [],\n            \"f1_score\":      [],\n            \"specificity\":   [],\n            \"learning_rate\": [],\n            \"epoch_time\":    []\n        }\n        self.precision   = Precision(task=\"multiclass\", num_classes=NUM_CLASSES, average=\"macro\").to(DEVICE)\n        self.recall      = Recall   (task=\"multiclass\", num_classes=NUM_CLASSES, average=\"macro\").to(DEVICE)\n        self.f1          = F1Score  (task=\"multiclass\", num_classes=NUM_CLASSES, average=\"macro\").to(DEVICE)\n        self.specificity = Specificity(task=\"multiclass\", num_classes=NUM_CLASSES, average=\"macro\").to(DEVICE)\n\n    def update(self, d):\n        for k,v in d.items():\n            if k in self.history:\n                self.history[k].append(v)\n\nclass TrainingVisualizer:\n    def __init__(self, save_dir=\"visualization_results\"):\n        self.save_dir = save_dir\n        os.makedirs(save_dir, exist_ok=True)\n        sns.set_theme()\n\n    def plot_comparison_metrics(self, mh, metrics, fname=\"metrics.png\"):\n        fig, ax = plt.subplots(len(metrics),1,figsize=(8,4*len(metrics)))\n        if len(metrics)==1: ax=[ax]\n        for i,m in enumerate(metrics):\n            for name,h in mh.items():\n                ax[i].plot(h[m], label=name)\n            ax[i].set_title(m.replace(\"_\",\" \").title()); ax[i].legend(); ax[i].grid(True)\n        plt.tight_layout(); plt.savefig(os.path.join(self.save_dir,fname)); plt.close()\n\n    def plot_class_performance(self, mh, fname=\"per_class.png\"):\n        fig, ax = plt.subplots(len(mh),1,figsize=(8,4*len(mh)))\n        if len(mh)==1: ax=[ax]\n        for i,(name,h) in enumerate(mh.items()):\n            for cls, vals in h[\"per_class_dice\"].items():\n                ax[i].plot(vals, label=cls)\n            ax[i].set_title(f\"{name} per-class Dice\"); ax[i].legend(); ax[i].grid(True)\n        plt.tight_layout(); plt.savefig(os.path.join(self.save_dir,fname)); plt.close()\n\n    def create_training_summary(self, mh, fname=\"summary.png\"):\n        fig = plt.figure(figsize=(12,10))\n        gs  = fig.add_gridspec(3,2)\n        ax1 = fig.add_subplot(gs[0,:])\n        for m,h in mh.items(): ax1.plot(h[\"train_loss\"], label=m)\n        ax1.set_title(\"Train Loss\"); ax1.legend(); ax1.grid(True)\n        ax2 = fig.add_subplot(gs[1,0])\n        for m,h in mh.items(): ax2.plot(h[\"val_dice\"], label=m)\n        ax2.set_title(\"Val Dice\"); ax2.legend(); ax2.grid(True)\n        ax3 = fig.add_subplot(gs[1,1])\n        for m,h in mh.items(): ax3.plot(h[\"val_hausdorff\"], label=m)\n        ax3.set_title(\"Val Hausdorff\"); ax3.legend(); ax3.grid(True)\n        ax4 = fig.add_subplot(gs[2,0])\n        mods = list(mh.keys()); x=np.arange(len(mods)); w=0.2\n        for i,met in enumerate([\"precision\",\"recall\",\"f1_score\"]):\n            vals=[np.mean(mh[m][met]) for m in mods]\n            ax4.bar(x+i*w, vals, w, label=met)\n        ax4.set_xticks(x+w); ax4.set_xticklabels(mods); ax4.set_title(\"Macro metrics\"); ax4.legend(); ax4.grid(True)\n        ax5 = fig.add_subplot(gs[2,1])\n        for m,h in mh.items(): ax5.plot(h[\"learning_rate\"], label=m)\n        ax5.set_title(\"LR\"); ax5.legend(); ax5.grid(True)\n        plt.tight_layout(); plt.savefig(os.path.join(self.save_dir,fname)); plt.close()\n\n    def plot_confusion_matrices(self, cms, fname=\"confusion.png\"):\n        valid = {n:cm for n,cm in cms.items() if isinstance(cm,np.ndarray)}\n        if not valid: return\n        fig, axs = plt.subplots(1,len(valid),figsize=(5*len(valid),4))\n        if len(valid)==1: axs=[axs]\n        for ax,(n,cm) in zip(axs, valid.items()):\n            sns.heatmap(cm, annot=True, fmt=\"d\", ax=ax,\n                        xticklabels=[LABEL_NAMES[i] for i in range(NUM_CLASSES)],\n                        yticklabels=[LABEL_NAMES[i] for i in range(NUM_CLASSES)])\n            ax.set_title(f\"{n} Confusion\"); ax.set_xlabel(\"Pred\"); ax.set_ylabel(\"True\")\n        plt.tight_layout(); plt.savefig(os.path.join(self.save_dir,fname)); plt.close()\n\n    def create_performance_report(self, mh, save_csv=\"performance_report.csv\"):\n        rows=[]\n        for m,h in mh.items():\n            rows.append({\n                \"Model\": m,\n                \"Best Dice\": max(h[\"val_dice\"]),\n                \"Final Dice\": h[\"val_dice\"][-1],\n                \"Precision\": np.mean(h[\"precision\"]),\n                \"Recall\":    np.mean(h[\"recall\"]),\n                \"F1 Score\":  np.mean(h[\"f1_score\"]),\n                \"Best Epoch\": int(np.argmax(h[\"val_dice\"])+1),\n                \"Final Loss\": h[\"train_loss\"][-1],\n                \"Final Hausdorff\": h[\"val_hausdorff\"][-1],\n            })\n        df = pd.DataFrame(rows)\n        df.to_csv(os.path.join(self.save_dir, save_csv), index=False)\n        return df\n\n\n# —————————————————————————————————————————————\n# 5) Utility metrics\n\ndef per_class_dice(pred, tgt):\n    out = {}\n    for cls in range(1, NUM_CLASSES):\n        p = (pred==cls).astype(np.float32)\n        t = (tgt==cls).astype(np.float32)\n        i = (p*t).sum(); u = p.sum()+t.sum()\n        out[f\"class_{cls}\"] = 2*i/(u+1e-8) if u>0 else 1.0\n    return out\n\ndef hausdorff(pred, tgt):\n    ds=[]\n    for cls in range(1, NUM_CLASSES):\n        pp, tt = np.argwhere(pred==cls), np.argwhere(tgt==cls)\n        if len(pp) and len(tt):\n            d1 = directed_hausdorff(pp, tt)[0]\n            d2 = directed_hausdorff(tt, pp)[0]\n            ds.append(max(d1,d2))\n    return ds\n\ndef compute_model_metrics(model, inp_shape):\n    m = copy.deepcopy(model).cpu().eval()\n    x = torch.randn(*inp_shape).cpu()\n    flops, params = profile(m, inputs=(x,), verbose=False)\n    return flops, params\n\n\n# —————————————————————————————————————————————\n# 6) Training & evaluation\n\ndef train_model(model, train_loader, val_loader, name,\n                max_epochs=50, patience=10, cbs=None):\n    model.to(DEVICE)\n    loss_fn = DiceCELoss(to_onehot_y=True, softmax=True)\n    opt     = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n    scaler  = torch.amp.GradScaler()\n    best_d, no_imp = -1, 0\n    tracker = MetricsTracker()\n    t0 = time.time()\n\n    if cbs:\n        for cb in cbs:\n            if hasattr(cb, \"attach_model\"):\n                cb.attach_model(model)\n\n    for ep in range(1, max_epochs+1):\n        print(f\"Epoch {ep}/{max_epochs}\")\n        t_ep = time.time()\n        model.train()\n        running_loss=0\n        for b in train_loader:\n            imgs = b[\"image\"].to(DEVICE)\n            lbls = b[\"label\"].to(DEVICE).unsqueeze(1)\n            opt.zero_grad()\n            with torch.amp.autocast(device_type='cuda'):\n                out  = model(imgs)\n                loss = loss_fn(out, lbls)\n            scaler.scale(loss).backward()\n            scaler.step(opt)\n            scaler.update()\n            running_loss += loss.item()\n        avg_loss = running_loss/len(train_loader)\n\n        model.eval()\n        dices, hauss = [], []\n        all_p, all_t = [], []\n        with torch.no_grad():\n            for i,b in enumerate(val_loader):\n                imgs = b[\"image\"].to(DEVICE)\n                lbls = b[\"label\"].to(DEVICE).flatten()\n                out  = sliding_window_inference(imgs,(64,64,64),4,model)\n                pr   = torch.argmax(out,dim=1).flatten()\n                all_p.append(pr); all_t.append(lbls)\n\n                pr_np = pr.cpu().numpy().reshape(b[\"label\"].shape[1:])\n                lb_np = b[\"label\"].cpu().numpy()[0]\n                dices.append(np.mean(list(per_class_dice(pr_np,lb_np).values())))\n                hauss.append(np.mean(hausdorff(pr_np, lb_np)))\n\n                if i==0:\n                    pc = per_class_dice(pr_np, lb_np)\n                    for k,v in pc.items():\n                        tracker.history[\"per_class_dice\"][k].append(v)\n\n        preds = torch.cat(all_p).to(DEVICE)\n        trues = torch.cat(all_t).to(DEVICE)\n        prec = tracker.precision(preds,trues).item()\n        rec  = tracker.recall   (preds,trues).item()\n        f1   = tracker.f1       (preds,trues).item()\n        spec = tracker.specificity(preds,trues).item()\n\n        m_d = np.mean(dices)\n        m_h = np.mean(hauss)\n        tracker.update({\n            \"train_loss\":    avg_loss,\n            \"val_dice\":      m_d,\n            \"val_hausdorff\": m_h,\n            \"precision\":     prec,\n            \"recall\":        rec,\n            \"f1_score\":      f1,\n            \"specificity\":   spec,\n            \"learning_rate\": opt.param_groups[0][\"lr\"]\n        })\n        tracker.history[\"epoch_time\"].append(time.time()-t_ep)\n\n        if cbs:\n            for cb in cbs:\n                cb.on_epoch_end(ep, {\"val_dice\":m_d,\"val_hausdorff\":m_h})\n\n        if m_d > best_d:\n            best_d = m_d\n            torch.save({\"model_state_dict\":model.state_dict()},\n                       f\"best_model_{name}.pth\")\n            no_imp = 0\n        else:\n            no_imp += 1\n            if no_imp >= patience:\n                print(\"Early stopping.\")\n                break\n\n    print(f\"{name} done in {time.time()-t0:.1f}s, best val_dice={best_d:.4f}\")\n    return best_d, time.time()-t0, tracker.history\n\n\ndef evaluate_best_model(model, name, val_loader, save_dir=\"visualization_results\"):\n    ckpt = torch.load(f\"best_model_{name}.pth\", map_location=DEVICE,weights_only=True)\n    model.load_state_dict(ckpt[\"model_state_dict\"])\n    model.to(DEVICE).eval()\n\n    all_p, all_t = [], []\n    pc_metrics = {f\"class_{i}\":{\"dice\":[],\"precision\":[],\"recall\":[],\"iou\":[],\"hd95\":[]} \n                  for i in range(1,NUM_CLASSES)}\n\n    with torch.no_grad():\n        for b in val_loader:\n            imgs = b[\"image\"].to(DEVICE)\n            lbl  = b[\"label\"].cpu().numpy()[0]\n            out  = sliding_window_inference(imgs,(64,64,64),4,model)\n            pr   = torch.argmax(out,dim=1).cpu().numpy()[0]\n            all_p.append(pr.flatten()); all_t.append(lbl.flatten())\n            for cls in range(1,NUM_CLASSES):\n                p = (pr==cls).astype(np.float32)\n                t = (lbl==cls).astype(np.float32)\n                tp = (p*t).sum(); fp=(p*(1-t)).sum(); fn=((1-p)*t).sum()\n                dice = 2*tp/(2*tp+fp+fn+1e-8)\n                prec = tp/(tp+fp+1e-8); rec=tp/(tp+fn+1e-8)\n                iou  = tp/(tp+fp+fn+1e-8)\n                if p.sum() and t.sum():\n                    d1 = directed_hausdorff(np.argwhere(p), np.argwhere(t))[0]\n                    d2 = directed_hausdorff(np.argwhere(t), np.argwhere(p))[0]\n                    hd  = max(d1,d2)\n                else:\n                    hd = np.nan\n                for met,val in zip([\"dice\",\"precision\",\"recall\",\"iou\",\"hd95\"],\n                                   [dice,prec,rec,iou,hd]):\n                    pc_metrics[f\"class_{cls}\"][met].append(val)\n\n    preds_flat = np.concatenate(all_p)\n    trues_flat = np.concatenate(all_t)\n    cm = confusion_matrix(trues_flat, preds_flat)\n\n    # save per-class CSV\n    df_pc = pd.DataFrame({\n        LABEL_NAMES[int(c.split(\"_\")[1])] : {\n            m: np.nanmean(vals) for m,vals in mets.items()\n        }\n        for c,mets in pc_metrics.items()\n    }).T\n    os.makedirs(save_dir, exist_ok=True)\n    df_pc.to_csv(os.path.join(save_dir, f\"{name}_per_class_metrics.csv\"))\n\n    macro = {\n        \"macro_precision\": np.mean([np.mean(m[\"precision\"]) for m in pc_metrics.values()]),\n        \"macro_recall\":    np.mean([np.mean(m[\"recall\"])    for m in pc_metrics.values()]),\n        \"macro_iou\":       np.mean([np.mean(m[\"iou\"])       for m in pc_metrics.values()])\n    }\n\n    return {\"per_class\": df_pc.to_dict(orient=\"index\"),\n            \"macro\":    macro,\n            \"confusion_matrix\": cm}\n\n\n# —————————————————————————————————————————————\n# 7) Main()\n\ndef main():\n    print(\"Collecting and loading data…\")\n    pairs = collect_pairs(IMAGES_DIR, LABELS_DIR)\n    images, labels = parallel_load(pairs)\n\n    idx = list(range(len(images)))\n    random.shuffle(idx)\n    split = int(0.8 * len(idx))\n    tr_idx, vl_idx = idx[:split], idx[split:]\n\n    train_ds = HippocampusDataset([images[i] for i in tr_idx],\n                                  [labels[i] for i in tr_idx])\n    val_ds   = HippocampusDataset([images[i] for i in vl_idx],\n                                  [labels[i] for i in vl_idx])\n\n    train_loader = DataLoader(train_ds, batch_size=1, shuffle=True,  num_workers=4)\n    val_loader   = DataLoader(val_ds,   batch_size=1, shuffle=False, num_workers=4)\n\n    models = {\n        \"UNet\":         UNet(3, IN_CHANNELS, NUM_CLASSES, (16,32,64,128,256), (2,2,2,2)),\n        \"VNet\":         VNet(3, IN_CHANNELS, NUM_CLASSES, dropout_prob_down=0.5, dropout_prob_up=(0.5,0.5)),\n        \"DynUNet\":      DynUNet(3, IN_CHANNELS, NUM_CLASSES,\n                                [[3]*3]*5,\n                                [[1]*3]+[[2]*3]*4,\n                                [[2]*3]*4,\n                                [8,16,32,64,128]),\n        \"RegUNet\":      RegUNet(3, IN_CHANNELS, NUM_CLASSES, depth=4, out_channels=NUM_CLASSES),\n        \"SegResNet\":    SegResNet(\n                spatial_dims=3,\n                init_filters=16,            # base number of feature maps\n                in_channels=IN_CHANNELS,    # 1\n                out_channels=NUM_CLASSES,   # 3\n                blocks_down=(1,1,1,2),\n                blocks_up=(1,1,1),\n                num_groups=4                 # optional: make sure num_channels % num_groups == 0\n            ),\n        \"UNETR\":     UNETR(\n                spatial_dims=3,\n                in_channels=IN_CHANNELS,\n                out_channels=NUM_CLASSES,\n                img_size=(64,64,64),\n                feature_size=16,\n                hidden_size=768,\n                mlp_dim=3072,\n                num_heads=12\n            ),\n        \"SwinUNETR\":    SwinUNETR(img_size=(64,64,64), in_channels=IN_CHANNELS,\n                                 out_channels=NUM_CLASSES, feature_size=48),\n        \"AttentionUnet\":AttentionUnet(3, IN_CHANNELS, NUM_CLASSES,\n                                      channels=(16,32,64,128,256), strides=(2,2,2,2)),\n        \"HighResNet\":   HighResNet(\n            spatial_dims=3,\n            in_channels=IN_CHANNELS,\n            out_channels=NUM_CLASSES)\n    }\n\n    results = {}\n    vis_cb = EnhancedVisCallback(val_loader)\n\n    for name, model in models.items():\n        print(f\"\\n=== {name} ===\")\n        fl, pa = compute_model_metrics(model, (1,IN_CHANNELS,64,64,64))\n        print(f\"{name}: {fl/1e9:.2f} GFLOPs, {(pa*4)/(1024**2):.2f} MB\")\n\n        best_d, tot_t, hist = train_model(\n            model, train_loader, val_loader, name,\n            max_epochs=50, patience=10, cbs=[]\n        )\n        perf = evaluate_best_model(model, name, val_loader)\n        results[name] = {\"history\": hist, \"confusion_matrix\": perf[\"confusion_matrix\"]}\n\n    viz = TrainingVisualizer()\n    mh  = {n:r[\"history\"]           for n,r in results.items()}\n    cms = {n:r[\"confusion_matrix\"]  for n,r in results.items()}\n\n    viz.plot_comparison_metrics(mh, [\"train_loss\",\"val_dice\",\"val_hausdorff\"])\n    viz.plot_class_performance(mh)\n    viz.create_training_summary(mh)\n    viz.plot_confusion_matrices(cms)\n    df_summary = viz.create_performance_report(mh)\n\n    print(\"\\nFinal performance summary:\\n\", df_summary)\n\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T10:18:31.946444Z","iopub.execute_input":"2025-04-30T10:18:31.946837Z","iopub.status.idle":"2025-04-30T12:05:04.215627Z","shell.execute_reply.started":"2025-04-30T10:18:31.946805Z","shell.execute_reply":"2025-04-30T12:05:04.214572Z"}},"outputs":[{"name":"stdout","text":"Collecting and loading data…\n\n=== UNet ===\nUNet: 2.55 GFLOPs, 7.55 MB\nEpoch 1/50\nEpoch 2/50\nEpoch 3/50\nEpoch 4/50\nEpoch 5/50\nEpoch 6/50\nEpoch 7/50\nEpoch 8/50\nEpoch 9/50\nEpoch 10/50\nEpoch 11/50\nEpoch 12/50\nEpoch 13/50\nEpoch 14/50\nEpoch 15/50\nEpoch 16/50\nEpoch 17/50\nEpoch 18/50\nEpoch 19/50\nEpoch 20/50\nEpoch 21/50\nEpoch 22/50\nEpoch 23/50\nEarly stopping.\nUNet done in 121.8s, best val_dice=0.8338\n\n=== VNet ===\nVNet: 96.00 GFLOPs, 173.96 MB\nEpoch 1/50\nEpoch 2/50\nEpoch 3/50\nEpoch 4/50\nEpoch 5/50\nEpoch 6/50\nEpoch 7/50\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n  return _methods._mean(a, axis=axis, dtype=dtype,\n/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n  ret = ret.dtype.type(ret / rcount)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/50\nEpoch 9/50\nEpoch 10/50\nEpoch 11/50\nEpoch 12/50\nEpoch 13/50\nEpoch 14/50\nEpoch 15/50\nEpoch 16/50\nEpoch 17/50\nEpoch 18/50\nEpoch 19/50\nEpoch 20/50\nEpoch 21/50\nEpoch 22/50\nEpoch 23/50\nEpoch 24/50\nEpoch 25/50\nEpoch 26/50\nEpoch 27/50\nEpoch 28/50\nEpoch 29/50\nEpoch 30/50\nEpoch 31/50\nEpoch 32/50\nEpoch 33/50\nEpoch 34/50\nEpoch 35/50\nEpoch 36/50\nEpoch 37/50\nEpoch 38/50\nEpoch 39/50\nEpoch 40/50\nEpoch 41/50\nEpoch 42/50\nEpoch 43/50\nEpoch 44/50\nEpoch 45/50\nEpoch 46/50\nEpoch 47/50\nEpoch 48/50\nEarly stopping.\nVNet done in 1324.6s, best val_dice=0.7281\n\n=== DynUNet ===\nDynUNet: 16.98 GFLOPs, 10.78 MB\nEpoch 1/50\nEpoch 2/50\nEpoch 3/50\nEpoch 4/50\nEpoch 5/50\nEpoch 6/50\nEpoch 7/50\nEpoch 8/50\nEpoch 9/50\nEpoch 10/50\nEpoch 11/50\nEpoch 12/50\nEpoch 13/50\nEpoch 14/50\nEpoch 15/50\nEpoch 16/50\nEpoch 17/50\nEpoch 18/50\nEpoch 19/50\nEpoch 20/50\nEpoch 21/50\nEpoch 22/50\nEpoch 23/50\nEpoch 24/50\nEpoch 25/50\nEpoch 26/50\nEpoch 27/50\nEpoch 28/50\nEpoch 29/50\nEpoch 30/50\nEpoch 31/50\nEpoch 32/50\nEpoch 33/50\nEpoch 34/50\nEpoch 35/50\nEpoch 36/50\nEpoch 37/50\nEpoch 38/50\nEpoch 39/50\nEpoch 40/50\nEpoch 41/50\nEpoch 42/50\nEpoch 43/50\nEarly stopping.\nDynUNet done in 342.2s, best val_dice=0.8375\n\n=== RegUNet ===\nRegUNet: 0.31 GFLOPs, 0.81 MB\nEpoch 1/50\nEpoch 2/50\nEpoch 3/50\nEpoch 4/50\nEpoch 5/50\nEpoch 6/50\nEpoch 7/50\nEpoch 8/50\nEpoch 9/50\nEpoch 10/50\nEpoch 11/50\nEpoch 12/50\nEpoch 13/50\nEpoch 14/50\nEpoch 15/50\nEpoch 16/50\nEpoch 17/50\nEpoch 18/50\nEpoch 19/50\nEpoch 20/50\nEpoch 21/50\nEpoch 22/50\nEpoch 23/50\nEpoch 24/50\nEpoch 25/50\nEpoch 26/50\nEpoch 27/50\nEpoch 28/50\nEpoch 29/50\nEpoch 30/50\nEpoch 31/50\nEpoch 32/50\nEpoch 33/50\nEpoch 34/50\nEpoch 35/50\nEpoch 36/50\nEpoch 37/50\nEpoch 38/50\nEpoch 39/50\nEpoch 40/50\nEpoch 41/50\nEpoch 42/50\nEpoch 43/50\nEpoch 44/50\nEpoch 45/50\nEarly stopping.\nRegUNet done in 254.0s, best val_dice=0.4191\n\n=== SegResNet ===\nSegResNet: 14.54 GFLOPs, 10.12 MB\nEpoch 1/50\nEpoch 2/50\nEpoch 3/50\nEpoch 4/50\nEpoch 5/50\nEpoch 6/50\nEpoch 7/50\nEpoch 8/50\nEpoch 9/50\nEpoch 10/50\nEpoch 11/50\nEpoch 12/50\nEpoch 13/50\nEpoch 14/50\nEpoch 15/50\nEpoch 16/50\nEpoch 17/50\nEpoch 18/50\nEpoch 19/50\nEpoch 20/50\nEpoch 21/50\nEpoch 22/50\nEpoch 23/50\nEpoch 24/50\nEpoch 25/50\nEpoch 26/50\nEpoch 27/50\nEpoch 28/50\nEpoch 29/50\nEpoch 30/50\nEpoch 31/50\nEpoch 32/50\nEpoch 33/50\nEpoch 34/50\nEpoch 35/50\nEpoch 36/50\nEpoch 37/50\nEpoch 38/50\nEpoch 39/50\nEpoch 40/50\nEpoch 41/50\nEpoch 42/50\nEpoch 43/50\nEpoch 44/50\nEpoch 45/50\nEpoch 46/50\nEpoch 47/50\nEpoch 48/50\nEpoch 49/50\nEpoch 50/50\nSegResNet done in 562.7s, best val_dice=0.8687\n\n=== UNETR ===\nUNETR: 24.46 GFLOPs, 353.31 MB\nEpoch 1/50\nEpoch 2/50\nEpoch 3/50\nEpoch 4/50\nEpoch 5/50\nEpoch 6/50\nEpoch 7/50\nEpoch 8/50\nEpoch 9/50\nEpoch 10/50\nEpoch 11/50\nEpoch 12/50\nEpoch 13/50\nEpoch 14/50\nEpoch 15/50\nEpoch 16/50\nEpoch 17/50\nEpoch 18/50\nEpoch 19/50\nEpoch 20/50\nEpoch 21/50\nEpoch 22/50\nEpoch 23/50\nEpoch 24/50\nEpoch 25/50\nEpoch 26/50\nEpoch 27/50\nEpoch 28/50\nEpoch 29/50\nEpoch 30/50\nEarly stopping.\nUNETR done in 693.1s, best val_dice=0.8451\n\n=== SwinUNETR ===\nSwinUNETR: 98.64 GFLOPs, 236.47 MB\nEpoch 1/50\nEpoch 2/50\nEpoch 3/50\nEpoch 4/50\nEpoch 5/50\nEpoch 6/50\nEpoch 7/50\nEpoch 8/50\nEpoch 9/50\nEpoch 10/50\nEpoch 11/50\nEpoch 12/50\nEpoch 13/50\nEpoch 14/50\nEpoch 15/50\nEpoch 16/50\nEpoch 17/50\nEpoch 18/50\nEpoch 19/50\nEpoch 20/50\nEpoch 21/50\nEpoch 22/50\nEpoch 23/50\nEpoch 24/50\nEpoch 25/50\nEpoch 26/50\nEpoch 27/50\nEpoch 28/50\nEpoch 29/50\nEpoch 30/50\nEpoch 31/50\nEpoch 32/50\nEarly stopping.\nSwinUNETR done in 1848.0s, best val_dice=0.8669\n\n=== AttentionUnet ===\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/thop/vision/calc_func.py:53: UserWarning: This API is being deprecated\n  warnings.warn(\"This API is being deprecated\")\n","output_type":"stream"},{"name":"stdout","text":"AttentionUnet: 18.31 GFLOPs, 22.54 MB\nEpoch 1/50\nEpoch 2/50\nEpoch 3/50\nEpoch 4/50\nEpoch 5/50\nEpoch 6/50\nEpoch 7/50\nEpoch 8/50\nEpoch 9/50\nEpoch 10/50\nEpoch 11/50\nEpoch 12/50\nEpoch 13/50\nEpoch 14/50\nEpoch 15/50\nEpoch 16/50\nEpoch 17/50\nEpoch 18/50\nEpoch 19/50\nEarly stopping.\nAttentionUnet done in 205.0s, best val_dice=0.7286\n\n=== HighResNet ===\nHighResNet: 212.46 GFLOPs, 3.09 MB\nEpoch 1/50\nEpoch 2/50\nEpoch 3/50\nEpoch 4/50\nEpoch 5/50\nEpoch 6/50\nEpoch 7/50\nEpoch 8/50\nEpoch 9/50\nEpoch 10/50\nEpoch 11/50\nEpoch 12/50\nEpoch 13/50\nEpoch 14/50\nEpoch 15/50\nEpoch 16/50\nEpoch 17/50\nEpoch 18/50\nEarly stopping.\nHighResNet done in 902.8s, best val_dice=0.5679\n\nFinal performance summary:\n            Model  Best Dice  Final Dice  Precision    Recall  F1 Score  \\\n0           UNet   0.833847    0.830391   0.863981  0.871808  0.866991   \n1           VNet   0.728091    0.707552   0.833184  0.771704  0.781677   \n2        DynUNet   0.837548    0.836554   0.829523  0.908471  0.863669   \n3        RegUNet   0.419073    0.385381   0.614537  0.585433  0.598006   \n4      SegResNet   0.868714    0.867317   0.901094  0.908588  0.904406   \n5          UNETR   0.845131    0.843860   0.870363  0.895010  0.881405   \n6      SwinUNETR   0.866943    0.861423   0.904707  0.905507  0.904832   \n7  AttentionUnet   0.728628    0.662614   0.683344  0.829593  0.738227   \n8     HighResNet   0.567906    0.430819   0.668493  0.695551  0.671210   \n\n   Best Epoch  Final Loss  Final Hausdorff  \n0          13    0.089366         5.264353  \n1          38    0.111797         8.676074  \n2          33    0.095302         5.149143  \n3          35    0.552137        17.873943  \n4          45    0.068944         5.716785  \n5          20    0.109858         6.262234  \n6          22    0.042151         7.436013  \n7           9    0.172134        23.085910  \n8           8    1.243493        35.529396  \n","output_type":"stream"}],"execution_count":7}]}